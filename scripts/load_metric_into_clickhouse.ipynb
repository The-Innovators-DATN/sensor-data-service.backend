{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2303193/1600285716.py:3: DtypeWarning: Columns (20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  england_water = pd.read_csv('../data/england_water_final.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common river basin: Humber\n",
      "Unnamed: 0.2            0\n",
      "Unnamed: 0.1            0\n",
      "Unnamed: 0              0\n",
      "datetime                0\n",
      "wqp                     0\n",
      "result                  0\n",
      "unit                    0\n",
      "station_type            0\n",
      "siteEasting             0\n",
      "siteNorthing            0\n",
      "year                    0\n",
      "month                   0\n",
      "hour                    0\n",
      "weekday                 0\n",
      "season                  0\n",
      "River Basin District    0\n",
      "Management Catchment    0\n",
      "Water Body ID           0\n",
      "Water Body              0\n",
      "Water Body Type         0\n",
      "Site ID                 0\n",
      "Site Region             0\n",
      "dtype: int64\n",
      "       Unnamed: 0.2  Unnamed: 0.1    Unnamed: 0         result    siteEasting  \\\n",
      "count  7.000300e+05  7.000300e+05  7.000300e+05  700030.000000  700030.000000   \n",
      "mean   5.086644e+06  5.882869e+06  5.882869e+06      76.709517  441683.289558   \n",
      "std    2.686528e+06  3.130144e+06  3.130144e+06     669.441570   34674.120212   \n",
      "min    8.934720e+05  1.062440e+06  1.062440e+06     -17.800000  380470.000000   \n",
      "25%    3.588784e+06  4.122361e+06  4.122361e+06       0.246000  415308.000000   \n",
      "50%    4.398988e+06  5.065010e+06  5.065010e+06       6.650000  439088.000000   \n",
      "75%    6.290828e+06  7.272584e+06  7.272584e+06      18.500000  460985.000000   \n",
      "max    1.694687e+07  1.972959e+07  1.972959e+07  210000.000000  539466.000000   \n",
      "\n",
      "        siteNorthing           year          month           hour  \\\n",
      "count  700030.000000  700030.000000  700030.000000  700030.000000   \n",
      "mean   377194.304660    2009.516726       6.471356      11.579049   \n",
      "std     65811.656045       6.261648       3.427659       1.990097   \n",
      "min    275100.000000    2000.000000       1.000000       0.000000   \n",
      "25%    319884.000000    2004.000000       3.000000      10.000000   \n",
      "50%    367812.000000    2010.000000       7.000000      11.000000   \n",
      "75%    429577.000000    2015.000000      10.000000      13.000000   \n",
      "max    517929.000000    2021.000000      12.000000      23.000000   \n",
      "\n",
      "             weekday  \n",
      "count  700030.000000  \n",
      "mean        3.927202  \n",
      "std         1.409072  \n",
      "min         1.000000  \n",
      "25%         3.000000  \n",
      "50%         4.000000  \n",
      "75%         5.000000  \n",
      "max         7.000000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "england_water = pd.read_csv('../data/england_water_final.csv')\n",
    "\n",
    "basin_counts = england_water['River Basin District'].value_counts()\n",
    "\n",
    "# Identify the river basin with the most records\n",
    "most_common_basin = basin_counts.idxmax()\n",
    "print(\"Most common river basin:\", most_common_basin)\n",
    "\n",
    "# Select only the data from that river basin\n",
    "england_water = england_water[england_water['River Basin District'] == most_common_basin]\n",
    "\n",
    "print(england_water.isnull().sum())  # Kiểm tra giá trị NaN\n",
    "print(england_water.describe())      # Kiểm tra giá trị bất thường"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2303193/4196422668.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  england_water_normalize['datetime'] = pd.to_datetime(england_water_normalize['datetime']).dt.tz_localize(None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>metric</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192930</th>\n",
       "      <td>1161</td>\n",
       "      <td>2018-10-03 09:35:00</td>\n",
       "      <td>Alky pH 4.5</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192931</th>\n",
       "      <td>1161</td>\n",
       "      <td>2018-07-05 12:32:00</td>\n",
       "      <td>Alky pH 4.5</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192932</th>\n",
       "      <td>1161</td>\n",
       "      <td>2018-05-02 14:35:00</td>\n",
       "      <td>Alky pH 4.5</td>\n",
       "      <td>281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192933</th>\n",
       "      <td>1161</td>\n",
       "      <td>2018-06-12 09:56:00</td>\n",
       "      <td>Alky pH 4.5</td>\n",
       "      <td>272.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192934</th>\n",
       "      <td>1161</td>\n",
       "      <td>2018-11-06 09:55:00</td>\n",
       "      <td>Alky pH 4.5</td>\n",
       "      <td>239.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       station_id            datetime       metric  value\n",
       "192930       1161 2018-10-03 09:35:00  Alky pH 4.5  225.0\n",
       "192931       1161 2018-07-05 12:32:00  Alky pH 4.5  268.0\n",
       "192932       1161 2018-05-02 14:35:00  Alky pH 4.5  281.0\n",
       "192933       1161 2018-06-12 09:56:00  Alky pH 4.5  272.0\n",
       "192934       1161 2018-11-06 09:55:00  Alky pH 4.5  239.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just kepp the columns we need: station_id, datetime, wqp, result, unit\n",
    "england_water_normalize = england_water[['Site ID', 'datetime', 'wqp', 'result']]\n",
    "\n",
    "# Then rename the columns to match the other datasets\n",
    "england_water_normalize.columns = ['station_id', 'datetime', 'metric', 'value']\n",
    "\n",
    "# Format data type of datetime without timezone, station_id to integer\n",
    "# england_water_normalize['station_id'] = england_water_normalize['station_id'].str.replace('GB-', '').astype(int)\n",
    "england_water_normalize['datetime'] = pd.to_datetime(england_water_normalize['datetime']).dt.tz_localize(None)\n",
    "\n",
    "england_water_normalize.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 700030 entries, 192930 to 3252897\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   station_id  700030 non-null  object        \n",
      " 1   datetime    700030 non-null  datetime64[ns]\n",
      " 2   metric      700030 non-null  object        \n",
      " 3   value       700030 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), object(2)\n",
      "memory usage: 26.7+ MB\n"
     ]
    }
   ],
   "source": [
    "england_water_normalize.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 672874 entries, 192930 to 1709664\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count   Dtype         \n",
      "---  ------      --------------   -----         \n",
      " 0   station_id  672874 non-null  int64         \n",
      " 1   datetime    672874 non-null  datetime64[ns]\n",
      " 2   metric      672874 non-null  object        \n",
      " 3   value       672874 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(1)\n",
      "memory usage: 25.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Just keep the rows where station_id is integer not a string\n",
    "england_water_normalize = england_water_normalize[england_water_normalize['station_id'].astype(str).apply(lambda x: x.isnumeric())]\n",
    "# Convert station_id to integer\n",
    "england_water_normalize['station_id'] = england_water_normalize['station_id'].astype(int)\n",
    "england_water_normalize.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'schema'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2303193/3933350110.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpa_csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyarrow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparquet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengland_water_normalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../data/england_water.parquet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'cat ../data/england_water.parquet | clickhouse-client --host 160.191.49.128 --port 9100 --user default --password shard1 --query=\"INSERT INTO station_metrics.messages_sharded format Parquet\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pyarrow/parquet/core.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(table, where, row_group_size, version, use_dictionary, compression, write_statistics, use_deprecated_int96_timestamps, coerce_timestamps, allow_truncated_timestamps, data_page_size, flavor, filesystem, compression_level, use_byte_stream_split, column_encoding, data_page_version, use_compliant_nested_type, encryption_properties, write_batch_size, dictionary_pagesize_limit, store_schema, write_page_index, write_page_checksum, sorting_columns, store_decimal_as_integer, **kwargs)\u001b[0m\n\u001b[1;32m   1931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1932\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_stringify_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1935\u001b[0;31m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'schema'"
     ]
    }
   ],
   "source": [
    "import pyarrow.csv as pa_csv\n",
    "import pyarrow.parquet as pq\n",
    "import subprocess\n",
    "\n",
    "## england_water_normalize is pandas DataFrame and I want to convert it to parquet file by england_water_normalize \n",
    "england_water_normalize.to_parquet('../data/england_water.parquet', index=False)\n",
    "\n",
    "cmd = f'cat ../data/england_water.parquet | clickhouse-client --host 160.191.49.128 --port 9100 --user default --password shard1 --query=\"INSERT INTO station_metrics.messages_sharded format Parquet\"'\n",
    "subprocess.run(cmd, shell=True, check=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
